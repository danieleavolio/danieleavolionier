<!DOCTYPE html>

<html lang="en">

<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width" />
	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="icon" href="/favicon.png" /> 
	<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
	<link rel="manifest" href="/site.webmanifest">	
		<link href="../_app/immutable/assets/0.b1fb99aa.css" rel="stylesheet">
		<link href="../_app/immutable/assets/8.100e037e.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.b05c4170.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/scheduler.69ed1edc.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/singletons.29cb9b2a.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/control.c2cf8273.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.82ae7dd8.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/preload-helper.a4192956.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.7977ad0e.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.a80dede6.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/config.2fe9a967.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/spread.8a54911c.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/Icon.dd186cdb.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/each.e59479a4.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.de1b60e2.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/8.21bf3639.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/dynamic-import-helper.be004503.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.8f2ca6db.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/utils.b7b94089.js"><title>Immersivaudio</title><!-- HEAD_svelte-ylbs26_START --><meta property="og:type" content="article"><meta property="og:title" content="Immersivaudio"><!-- HEAD_svelte-ylbs26_END -->
	<meta name="google-site-verification" content="FTolVaK-x02wu54OEQqZv2yP7npBnNRQtI6mSv8W4RQ" />
</head>

<body data-sveltekit-preload-data="hover">
	<div style="display: contents">  <div class="layout svelte-yzgd0o"> <nav class="svelte-1chnx4l"><div class="nav-div svelte-1chnx4l">  <div class="home svelte-1chnx4l"><svg xmlns="http://www.w3.org/2000/svg" width="2.5em" height="2.5em" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" cursor="pointer" fill-opacity="0" class="lucide-icon lucide lucide-home "><path d="m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path><polyline points="9 22 9 12 15 12 15 22"></polyline></svg></div>  <div class="button-hamburger svelte-1chnx4l"><svg xmlns="http://www.w3.org/2000/svg" width="2.5em" height="2.5em" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" fill-opacity="0" class="lucide-icon lucide lucide-settings "><path d="M12.22 2h-.44a2 2 0 0 0-2 2v.18a2 2 0 0 1-1 1.73l-.43.25a2 2 0 0 1-2 0l-.15-.08a2 2 0 0 0-2.73.73l-.22.38a2 2 0 0 0 .73 2.73l.15.1a2 2 0 0 1 1 1.72v.51a2 2 0 0 1-1 1.74l-.15.09a2 2 0 0 0-.73 2.73l.22.38a2 2 0 0 0 2.73.73l.15-.08a2 2 0 0 1 2 0l.43.25a2 2 0 0 1 1 1.73V20a2 2 0 0 0 2 2h.44a2 2 0 0 0 2-2v-.18a2 2 0 0 1 1-1.73l.43-.25a2 2 0 0 1 2 0l.15.08a2 2 0 0 0 2.73-.73l.22-.39a2 2 0 0 0-.73-2.73l-.15-.08a2 2 0 0 1-1-1.74v-.5a2 2 0 0 1 1-1.74l.15-.09a2 2 0 0 0 .73-2.73l-.22-.38a2 2 0 0 0-2.73-.73l-.15.08a2 2 0 0 1-2 0l-.43-.25a2 2 0 0 1-1-1.73V4a2 2 0 0 0-2-2z"></path><circle cx="12" cy="12" r="3"></circle></svg></div></div></nav>  <main class="svelte-yzgd0o"><div class="transition svelte-vcdv4c">  <article class="svelte-lu8bqq"> <hgroup><h1 class="svelte-lu8bqq">Immersivaudio</h1> <p class="svelte-lu8bqq">Writing date: 2 giu 2024</p></hgroup>  <div class="tags svelte-lu8bqq"><span class="surface-4 svelte-lu8bqq">#PYTHON</span><span class="surface-4 svelte-lu8bqq">#PYTORCH</span><span class="surface-4 svelte-lu8bqq">#GRADIO</span><span class="surface-4 svelte-lu8bqq">#AI</span></div>  <div class="prose svelte-lu8bqq"><h2 id="panoramica-del-progetto" data-svelte-h="svelte-auew2e">Panoramica del Progetto</h2> <p data-svelte-h="svelte-8cjd6d">Immersivaudio è un progetto innovativo che trasforma contenuti visivi in musica utilizzando la potenza dell’intelligenza artificiale. Estraendo e analizzando fotogrammi dai video, il progetto utilizza tecniche avanzate di AI per generare prompt descrittivi che vengono poi convertiti in musica. Questa fusione tra visione artificiale, elaborazione del linguaggio naturale e generazione musicale crea un’esperienza audio-visiva unica e immersiva.</p> <img src="https://i.imgur.com/A3AmTK6.png" alt="Immersivaudio" loading="lazy"> <h2 id="tecnologie-utilizzate" data-svelte-h="svelte-e5xol3">Tecnologie Utilizzate</h2> <h3 id="python" data-svelte-h="svelte-pgxl48">Python</h3> <p data-svelte-h="svelte-1n3ohu5">Il linguaggio di programmazione principale utilizzato per sviluppare i vari script e algoritmi del progetto.</p> <h3 id="pytorch" data-svelte-h="svelte-i2m0oe">PyTorch</h3> <p data-svelte-h="svelte-b3v28g">Utilizzato per costruire e addestrare i modelli di AI, specialmente per il rilevamento di oggetti e la generazione musicale.</p> <h3 id="gradio" data-svelte-h="svelte-1i3psys">Gradio</h3> <p data-svelte-h="svelte-znzv2g">Fornisce un’interfaccia facile da usare per eseguire il progetto e interagire con i modelli AI.</p> <h2 id="caratteristiche-principali-e-script" data-svelte-h="svelte-9c36r5">Caratteristiche Principali e Script</h2> <h3 id="generazione-musicale" data-svelte-h="svelte-1je6zbr">Generazione Musicale</h3> <ul data-svelte-h="svelte-5ovnps"><li><strong>audioldm2.py</strong>: Questo script prende prompt descrittivi e genera la musica corrispondente, creando una colonna sonora che riflette il contenuto visivo.</li></ul> <h3 id="analisi-dei-fotogrammi" data-svelte-h="svelte-1b6xwb4">Analisi dei Fotogrammi</h3> <ul data-svelte-h="svelte-1twegpm"><li><strong>best_frame_selection.py</strong>: Implementa un algoritmo di clustering k-medoidi per selezionare i fotogrammi più rappresentativi da un video, garantendo la massima qualità dell’input per ulteriori analisi.</li> <li><strong>frame_extractor.py</strong>: Estrae fotogrammi dai file video utilizzando una formula specifica, preparandoli per il rilevamento di oggetti e la generazione di descrizioni.</li></ul> <h3 id="rilevamento-e-descrizione-degli-oggetti" data-svelte-h="svelte-1hsn116">Rilevamento e Descrizione degli Oggetti</h3> <ul data-svelte-h="svelte-frerbs"><li><strong>yolov9.py</strong>: Utilizza il modello YOLOv9 per rilevare oggetti all’interno dei fotogrammi video, fornendo informazioni dettagliate sul contenuto di ogni fotogramma.</li> <li><strong>moondream2.py</strong>: Genera descrizioni testuali dai fotogrammi specifici, traducendo le informazioni visive in un formato adatto per la generazione musicale.</li></ul> <img src="https://i.imgur.com/3Shji5F.png" alt="YoloV9" loading="lazy"> <h3 id="integrazione-e-interfaccia" data-svelte-h="svelte-km3ez0">Integrazione e Interfaccia</h3> <ul data-svelte-h="svelte-ogawnn"><li><strong>gradio_interface.py</strong>: Crea un’interfaccia user-friendly con Gradio, permettendo agli utenti di eseguire facilmente il progetto e interagire con i componenti AI.</li> <li><strong>prompt_combiner.py</strong>: Combina i risultati degli script di descrizione dei fotogrammi e rilevamento degli oggetti per generare prompt completi per il processo di generazione musicale.</li> <li><strong>video_reconstructor.py</strong>: Reintegra la musica generata con il video originale, producendo un prodotto finale che armonizza elementi audio e visivi.</li> <li><strong>main.py</strong>: Sovraintende l’intero workflow, assicurando un’operazione fluida dall’input video all’output musicale.</li></ul> <img src="https://i.imgur.com/is1SWhV.png" alt="Interfaccia" loading="lazy"> <h2 id="notebook" data-svelte-h="svelte-3fv7ni">Notebook</h2> <p data-svelte-h="svelte-dn56za">Diversi notebook Jupyter (.ipynb) accompagnano il progetto, illustrando l’uso degli script e il workflow complessivo di elaborazione video. Anche se questi notebook sono stati rimossi nell’ultimo commit, rimangono accessibili nelle versioni precedenti del repository.</p> <h2 id="istruzioni-per-luso" data-svelte-h="svelte-1118fw3">Istruzioni per l’Uso</h2> <h3 id="google-colab" data-svelte-h="svelte-z7xdup">Google Colab</h3> <p data-svelte-h="svelte-fvvk0z">Per gli utenti senza una GPU, Google Colab offre una piattaforma conveniente per eseguire il progetto. Il notebook <code>Immersiveaudio_Colab.ipynb</code> fornisce una guida dettagliata per eseguire il progetto nel cloud, sfruttando le risorse di Colab per l’elaborazione AI.</p> <h3 id="macchina-locale" data-svelte-h="svelte-du4m5p">Macchina Locale</h3> <p data-svelte-h="svelte-1lubdiq">Gli utenti con una GPU ad alte prestazioni e capacità CUDA possono eseguire il progetto localmente. Dopo aver installato le dipendenze necessarie, lo script <code>gradio_interface.py</code> può essere eseguito per avviare l’interfaccia Gradio e iniziare il processo di generazione musicale.</p> <p data-svelte-h="svelte-1375d0z">Per esplorare il progetto completo e accedere al codice, visita il <a href="https://github.com/danieleavolio/Immersivaudio" rel="nofollow">repository GitHub</a>.</p> <h3 align="center" data-svelte-h="svelte-6bzeh3">Esempio di Video</h3> <video style="margin:auto" width="320" height="240" controls data-svelte-h="svelte-fdhvgx"><source src="https://i.imgur.com/3kZ3CVA.mp4" type="video/mp4">
    Il tuo browser non supporta il tag video.</video> <h2 id="conclusione" data-svelte-h="svelte-1famsre">Conclusione</h2> <p data-svelte-h="svelte-1xjxaj">Ecco tutto. Ho lavorato a questo progetto con altre due persone:</p> <ul data-svelte-h="svelte-i75xki"><li><a href="https://github.com/danieleavolio" rel="nofollow">Daniele Avolio</a></li> <li><a href="https://github.com/maikuvit" rel="nofollow">Michele Vitale</a></li> <li><a href="https://github.com/pythonTedo" rel="nofollow">Teodor Chakarov</a></li></ul> <p data-svelte-h="svelte-l2083t">È stato un progetto molto interessante e abbiamo imparato molto su AI, generazione musicale e visione artificiale. Ci vediamo nel prossimo progetto! 🚀</p> <hr></div> </article></div></main> <footer class="svelte-k2ae0s"><p class="svelte-k2ae0s">Daniele Avolio © 2024</p> </footer> </div> 
			
			<script>
				{
					__sveltekit_eosok9 = {
						base: new URL("..", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("../_app/immutable/entry/start.b05c4170.js"),
						import("../_app/immutable/entry/app.82ae7dd8.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 8],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
</body>

</html>