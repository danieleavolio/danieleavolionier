import{s as De,v as se,w as Re,f as s,a as o,g as r,B as m,c as a,j as v,i,u as We,d as l}from"./scheduler.a5f99357.js";import{S as ke,i as Fe,b as re,d as me,m as ue,a as pe,t as de,e as ce}from"./index.0f8e246b.js";import{g as Ve,a as Se}from"./spread.8a54911c.js";import{M as Ae}from"./mdsvex.7659b120.js";import{I as Ue}from"./img.c6ac5925.js";function Ge(D){let n,x="Sistema di Rilevamento delle Emozioni",f,d,u="Questo progetto è progettato per rilevare e analizzare le emozioni dai flussi video in tempo reale. Utilizza un <strong>pretrained</strong> per identificare i volti umani e <strong>FER</strong> per classificare le loro emozioni in diverse categorie come <em>neutro, felice, triste, sorpresa, paura, disgusto e arrabbiato</em>. Il sistema traccia anche l’andamento delle emozioni dominanti nel tempo, fornendo preziose informazioni sulle dinamiche emotive. Lo scopo principale era quello di realizzare un’interfaccia grafica semplice e che fosse facile da usare, per poter essere utilizzata da chiunque.",p,c,ve="Caratteristiche",W,L,fe="<li>Rilevamento delle emozioni in tempo reale dai flussi video.</li> <li>Identificazione di emozioni multiple.</li> <li>Analisi dell’andamento delle emozioni dominanti nel tempo.</li> <li>Leggero ed efficiente, adatto per essere eseguito su varie piattaforme hardware.</li> <li>Plug-and-play, facile da fare partire.</li>",k,C,xe="Esempio",F,z,Ce="Esempio di Rilevamento delle Emozioni",V,P,A,M,G,_,ze="Installazione",B,w,_e="Controllare la repository <em>github</em> per clonare il progetto e installare le dipendenze necessarie. Tutte le informazioni sono disponibili nel file <code>requirements.txt</code>.",N,b,be="Utilizzo",O,T,he="Per avviare il sistema di rilevamento delle emozioni, esegui lo script principale dal terminale.",Q,h,ge="Parametri",J,E,$e="<li><code>--analyze_video</code>: Dopo aver premuto <code>q</code> per interrompere il flusso video, verrà salvato un file PNG con l’andamento delle emozioni nel tempo.</li>",K,g,He="Complicazioni e Limitazioni",X,y,qe="Attualmente il progetto funziona solamente con 1 volto alla volta e non è in grado di rilevare emozioni da volti parzialmente visibili o coperti. Inoltre, la precisione del rilevamento delle emozioni può variare in base alla qualità dell’immagine e alla luce ambientale. Il modello è molto molto leggero appunto per funzionare in tempo reale, quindi non è il più accurato in assoluto; piuttosto è un buon compromesso tra accuratezza e velocità.",Y,I,Le="Posso dire che in condizioni di scarsa luce si comporta comunque in modo accettabile e con una webcam abbastanza di scarsa qualità, quindi è un buon compromesso per un uso generale.",Z,$,Pe="Risolvere le Complicazioni",ee,R,Me="Semplicemente utilizzando un modello più complesso e pesante, si potrebbe migliorare la precisione del rilevamento delle emozioni. Tuttavia, questo comporterebbe un aumento dei requisiti di elaborazione e potrebbe compromettere la velocità di esecuzione in tempo reale rendendola pressoché impossibile con hardware di fascia bassa e non specificatamente dedicato. Comunque, dopo vari test ho notato che utilizzando una webcam con qualità maggiore il risultato è molto più preciso.",te,H,we="Future implementazioni",ie,S,Te="<li>Migliorare la precisione del rilevamento delle emozioni.</li> <li>Supporto per il rilevamento di più volti contemporaneamente.</li> <li>Possibilità di usare un file video come input.</li> <li>Possibilità d i usare un’immagine come input.</li>",le,q,Ee="Conclusione",ne,U,ye='Puoi trovare il progetto sulla pagina <strong>github</strong> qui <a href="https://github.com/danieleavolio/WebcamEmotionDetection" rel="nofollow">Webcam Emotion Detection</a>!',oe,j,Ie="Per qualsiasi domanda o suggerimento, non esitare a contattarmi!",ae;return P=new Ue({props:{src:"https://i.imgur.com/iImMGgz.png",alt:"Esempio di Emozioni"}}),M=new Ue({props:{src:"https://i.imgur.com/el8560V.png",alt:"Esempio di Emozioni"}}),{c(){n=s("h1"),n.textContent=x,f=o(),d=s("p"),d.innerHTML=u,p=o(),c=s("h2"),c.textContent=ve,W=o(),L=s("ul"),L.innerHTML=fe,k=o(),C=s("h2"),C.textContent=xe,F=o(),z=s("h3"),z.textContent=Ce,V=o(),re(P.$$.fragment),A=o(),re(M.$$.fragment),G=o(),_=s("h2"),_.textContent=ze,B=o(),w=s("p"),w.innerHTML=_e,N=o(),b=s("h2"),b.textContent=be,O=o(),T=s("p"),T.textContent=he,Q=o(),h=s("h3"),h.textContent=ge,J=o(),E=s("ul"),E.innerHTML=$e,K=o(),g=s("h2"),g.textContent=He,X=o(),y=s("p"),y.textContent=qe,Y=o(),I=s("p"),I.textContent=Le,Z=o(),$=s("h2"),$.textContent=Pe,ee=o(),R=s("p"),R.textContent=Me,te=o(),H=s("h2"),H.textContent=we,ie=o(),S=s("ul"),S.innerHTML=Te,le=o(),q=s("h2"),q.textContent=Ee,ne=o(),U=s("p"),U.innerHTML=ye,oe=o(),j=s("p"),j.textContent=Ie,this.h()},l(e){n=r(e,"H1",{id:!0,"data-svelte-h":!0}),m(n)!=="svelte-1r7rl0"&&(n.textContent=x),f=a(e),d=r(e,"P",{"data-svelte-h":!0}),m(d)!=="svelte-1dg7hr9"&&(d.innerHTML=u),p=a(e),c=r(e,"H2",{id:!0,"data-svelte-h":!0}),m(c)!=="svelte-hno1ww"&&(c.textContent=ve),W=a(e),L=r(e,"UL",{"data-svelte-h":!0}),m(L)!=="svelte-5rlr8y"&&(L.innerHTML=fe),k=a(e),C=r(e,"H2",{id:!0,"data-svelte-h":!0}),m(C)!=="svelte-1ay61m6"&&(C.textContent=xe),F=a(e),z=r(e,"H3",{id:!0,"data-svelte-h":!0}),m(z)!=="svelte-erv5k0"&&(z.textContent=Ce),V=a(e),me(P.$$.fragment,e),A=a(e),me(M.$$.fragment,e),G=a(e),_=r(e,"H2",{id:!0,"data-svelte-h":!0}),m(_)!=="svelte-x3cgds"&&(_.textContent=ze),B=a(e),w=r(e,"P",{"data-svelte-h":!0}),m(w)!=="svelte-1wa35lg"&&(w.innerHTML=_e),N=a(e),b=r(e,"H2",{id:!0,"data-svelte-h":!0}),m(b)!=="svelte-o1srji"&&(b.textContent=be),O=a(e),T=r(e,"P",{"data-svelte-h":!0}),m(T)!=="svelte-tbrrdg"&&(T.textContent=he),Q=a(e),h=r(e,"H3",{id:!0,"data-svelte-h":!0}),m(h)!=="svelte-90amaq"&&(h.textContent=ge),J=a(e),E=r(e,"UL",{"data-svelte-h":!0}),m(E)!=="svelte-1c179l6"&&(E.innerHTML=$e),K=a(e),g=r(e,"H2",{id:!0,"data-svelte-h":!0}),m(g)!=="svelte-2cxvy8"&&(g.textContent=He),X=a(e),y=r(e,"P",{"data-svelte-h":!0}),m(y)!=="svelte-1og4eag"&&(y.textContent=qe),Y=a(e),I=r(e,"P",{"data-svelte-h":!0}),m(I)!=="svelte-1hd7gj2"&&(I.textContent=Le),Z=a(e),$=r(e,"H2",{id:!0,"data-svelte-h":!0}),m($)!=="svelte-q3lvqs"&&($.textContent=Pe),ee=a(e),R=r(e,"P",{"data-svelte-h":!0}),m(R)!=="svelte-c9bc9u"&&(R.textContent=Me),te=a(e),H=r(e,"H2",{id:!0,"data-svelte-h":!0}),m(H)!=="svelte-kk0duz"&&(H.textContent=we),ie=a(e),S=r(e,"UL",{"data-svelte-h":!0}),m(S)!=="svelte-1npq77p"&&(S.innerHTML=Te),le=a(e),q=r(e,"H2",{id:!0,"data-svelte-h":!0}),m(q)!=="svelte-1famsre"&&(q.textContent=Ee),ne=a(e),U=r(e,"P",{"data-svelte-h":!0}),m(U)!=="svelte-ihfpv4"&&(U.innerHTML=ye),oe=a(e),j=r(e,"P",{"data-svelte-h":!0}),m(j)!=="svelte-19fwvc1"&&(j.textContent=Ie),this.h()},h(){v(n,"id","sistema-di-rilevamento-delle-emozioni"),v(c,"id","caratteristiche"),v(C,"id","esempio"),v(z,"id","esempio-di-rilevamento-delle-emozioni"),v(_,"id","installazione"),v(b,"id","utilizzo"),v(h,"id","parametri"),v(g,"id","complicazioni-e-limitazioni"),v($,"id","risolvere-le-complicazioni"),v(H,"id","future-implementazioni"),v(q,"id","conclusione")},m(e,t){i(e,n,t),i(e,f,t),i(e,d,t),i(e,p,t),i(e,c,t),i(e,W,t),i(e,L,t),i(e,k,t),i(e,C,t),i(e,F,t),i(e,z,t),i(e,V,t),ue(P,e,t),i(e,A,t),ue(M,e,t),i(e,G,t),i(e,_,t),i(e,B,t),i(e,w,t),i(e,N,t),i(e,b,t),i(e,O,t),i(e,T,t),i(e,Q,t),i(e,h,t),i(e,J,t),i(e,E,t),i(e,K,t),i(e,g,t),i(e,X,t),i(e,y,t),i(e,Y,t),i(e,I,t),i(e,Z,t),i(e,$,t),i(e,ee,t),i(e,R,t),i(e,te,t),i(e,H,t),i(e,ie,t),i(e,S,t),i(e,le,t),i(e,q,t),i(e,ne,t),i(e,U,t),i(e,oe,t),i(e,j,t),ae=!0},p:We,i(e){ae||(pe(P.$$.fragment,e),pe(M.$$.fragment,e),ae=!0)},o(e){de(P.$$.fragment,e),de(M.$$.fragment,e),ae=!1},d(e){e&&(l(n),l(f),l(d),l(p),l(c),l(W),l(L),l(k),l(C),l(F),l(z),l(V),l(A),l(G),l(_),l(B),l(w),l(N),l(b),l(O),l(T),l(Q),l(h),l(J),l(E),l(K),l(g),l(X),l(y),l(Y),l(I),l(Z),l($),l(ee),l(R),l(te),l(H),l(ie),l(S),l(le),l(q),l(ne),l(U),l(oe),l(j)),ce(P,e),ce(M,e)}}}function Be(D){let n,x;const f=[D[0],je];let d={$$slots:{default:[Ge]},$$scope:{ctx:D}};for(let u=0;u<f.length;u+=1)d=se(d,f[u]);return n=new Ae({props:d}),{c(){re(n.$$.fragment)},l(u){me(n.$$.fragment,u)},m(u,p){ue(n,u,p),x=!0},p(u,[p]){const c=p&1?Ve(f,[p&1&&Se(u[0]),p&0&&Se(je)]):{};p&2&&(c.$$scope={dirty:p,ctx:u}),n.$set(c)},i(u){x||(pe(n.$$.fragment,u),x=!0)},o(u){de(n.$$.fragment,u),x=!1},d(u){ce(n,u)}}}const je={title:"Webcam Emotion Detection",description:"Piccolo progettod di Machine Learning per rilevare le emozioni umane tramite la webcam, lightweigth e facile da usare.",date:"07-04-2024-16:00",categories:["Machine Learning","Computer Vision","Python","OpenCV","TensorFlow"],published:!0};function Ne(D,n,x){return D.$$set=f=>{x(0,n=se(se({},n),Re(f)))},n=Re(n),[n]}class Ye extends ke{constructor(n){super(),Fe(this,n,Ne,Be,De,{})}}export{Ye as default,je as metadata};
